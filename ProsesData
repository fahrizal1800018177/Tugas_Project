>>> sars_df.show(5)
+----------+--------------------+----------------------------+----------------+----------------+
|      Date|             Country|Cumulative number of case(s)|Number of deaths|Number recovered|
+----------+--------------------+----------------------------+----------------+----------------+
|2003-03-17|             Germany|                           1|               0|               0|
|2003-03-17|              Canada|                           8|               2|               0|
|2003-03-17|           Singapore|                          20|               0|               0|
|2003-03-17|Hong Kong SAR, China|                          95|               1|               0|
|2003-03-17|         Switzerland|                           2|               0|               0|
+----------+--------------------+----------------------------+----------------+----------------+
only showing top 5 rows

 sars_df.printSchema()
root
 |-- Date: string (nullable = true)
 |-- Country: string (nullable = true)
 |-- Cumulative number of case(s): integer (nullable = true)
 |-- Number of deaths: integer (nullable = true)
 |-- Number recovered: integer (nullable = true)
sars_df = spark.read.csv('C:/BigData/Sars.csv', header=True, inferSchema=True)
>>> sars_country = sars_df.filter(sars_df.Country == 1)
>>> sars_country.count()
0
